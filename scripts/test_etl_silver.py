"""
Script de Prueba FASE 3: ETL Bronze -> Silver
Busca el primer batch real en Bronze y lo transforma.
"""

import sys
import os
import json
import pandas as pd

# A√±adimos la ra√≠z del proyecto al path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.etl.bronze_to_silver import BronzeToSilverETL
from src.storage.minio_client import MinIOStorageClient

def find_any_bronze_file():
    """Busca recursivamente el primer archivo JSON en el bucket Bronze"""
    client = MinIOStorageClient()
    bronze_bucket = os.getenv("S3_BUCKET_BRONZE", "bronze")
    
    print(f"üîç Buscando archivos en bucket '{bronze_bucket}'...")
    
    # Listamos objetos (paginaci√≥n autom√°tica de boto3)
    paginator = client.s3.get_paginator('list_objects_v2')
    pages = paginator.paginate(Bucket=bronze_bucket, Prefix='wow_raid_events/')
    
    for page in pages:
        if 'Contents' in page:
            for obj in page['Contents']:
                key = obj['Key']
                if key.endswith('.json'):
                    return key
    return None

def main():
    print("="*60)
    print("üöÄ INICIANDO TEST ETL (BRONZE -> SILVER)")
    print("="*60)
    
    # 1. Encontrar un archivo real para probar
    bronze_key = find_any_bronze_file()
    
    if not bronze_key:
        print("‚ùå ERROR CR√çTICO: No se encontraron archivos JSON en Bronze.")
        print("   Aseg√∫rate de haber corrido la Fase 2 o inyecta datos manualmente.")
        return

    print(f"‚úÖ Archivo encontrado: {bronze_key}")
    
    # 2. Ejecutar ETL
    print("\n‚ö° Ejecutando transformaci√≥n...")
    etl = BronzeToSilverETL()
    
    try:
        result = etl.run(bronze_key)
        
        if result['status'] == 'success':
            meta = result['metadata']
            store = result['storage']
            
            print("\nüéâ √âXITO: Transformaci√≥n completada")
            print(f"   - Eventos procesados: {meta.get('rows_after_validation', 'N/A')}")
            print(f"   - Duplicados eliminados: {meta.get('duplicates_removed', 0)}")
            print(f"   - Ruta Parquet: {store['s3_path']}")
            print(f"   - Tama√±o original (JSON): ~{os.path.getsize(bronze_key) if os.path.exists(bronze_key) else 'N/A'} bytes (estimado)")
            print(f"   - Tama√±o final (Parquet): {store['bytes']} bytes")
            
            # Verificaci√≥n r√°pida del Parquet (lectura de vuelta)
            print("\nüîé Verificando integridad del archivo Parquet...")
            df_check = pd.read_parquet(
                store['s3_path'].replace("s3://", f"{etl.storage.endpoint_url}/").replace(etl.storage.endpoint_url + "/" + etl.bucket_silver, f"s3://{etl.bucket_silver}"),
                storage_options={
                    "key": etl.storage.access_key,
                    "secret": etl.storage.secret_key,
                    "client_kwargs": {"endpoint_url": etl.storage.endpoint_url}
                }
            )
            print(f"   ‚úÖ Le√≠do correctamente con Pandas. Columnas: {list(df_check.columns)}")
            
        else:
            print(f"\n‚ö†Ô∏è SKIPPED: {result.get('reason')}")
            
    except Exception as e:
        print(f"\n‚ùå ERROR EN ETL: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
