# WoW Raid Telemetry Pipeline

**Proyecto de Curso:** Big Data e Inteligencia Artificial   
**Autor:** Byron V. Blatch Rodriguez   
**Profesor:** Francisco Javier Ortega   
**Repositorio:** [github.com/Vincent0675/raid-savior](https://github.com/Vincent0675/raid-savior)   
**Estado:** Fase 4 (Gold) completada. Fase E (PySpark) en curso.   
**√öltima actualizaci√≥n:** 25 de febrero de 2026.   

***

## 1. Visi√≥n general

Pipeline de telemetr√≠a **event-driven** que simula raids de World of Warcraft
sobre una arquitectura **Medallion** completa (Bronze ‚Üí Silver ‚Üí Gold) con
almacenamiento en MinIO (S3-compatible), validaci√≥n estricta con Pydantic v2
y formato columnar Parquet en Silver/Gold.

**Resultados actuales del dataset de producci√≥n:**


| M√©trica | Valor |
| :-- | :-- |
| Eventos ingresados | 505.000 (10 raids √ó 50.500) |
| Archivos Bronze | 1.010 JSON ‚Äî 546.9 MB |
| Archivos Silver | 1.010 Parquet (Snappy) |
| Particiones Gold | 10 (1 por raid) |
| Da√±o total acumulado | 4.866.754.996 |
| Jugadores √∫nicos | 200 |
| Coherencia Gold | ‚úÖ 0 fallos |


***

## 2. Integraci√≥n acad√©mica por asignatura

El proyecto sirve como **n√∫cleo com√∫n** para las cuatro asignaturas de la especializaci√≥n, usando la arquitectura Medallion como hilo conductor.

### 2.1 Big Data Aplicado (BDA)

En esta asignatura demuestro dominio de:

- **Arquitectura Medallion completa** sobre object storage (MinIO): dise√±o y operaci√≥n de las capas Bronze, Silver y Gold con contratos de escritura claros y particionamiento l√≥gico por `raid_id` y `event_date`.  
- **Formatos columnar y optimizaci√≥n de coste**: migraci√≥n de JSON a Parquet + Snappy en Silver/Gold, explicando ratios de compresi√≥n, predicate pushdown y ventajas frente a almacenamiento row-based.   
- **Modelado de tablas semidimensionales en Gold**: dise√±o de `dim_player`, `dim_raid` y facts (`fact_raid_summary`, `fact_player_raid_stats`) como base de anal√≠tica y ML. 

### 2.2 Sistemas de Big Data

En Sistemas de Big Data el foco est√° en la **operacionalizaci√≥n** del pipeline:

- **Ingesta event-driven y observabilidad**: receptor HTTP Flask, logs detallados por batch, m√©tricas de throughput y latencia de ingesta, y scripts de inspecci√≥n (`inspect_bronze_vs_silver`, `inspect_gold`).   
- **Infraestructura contenedorizada**: despliegue de MinIO y servicios auxiliares con Docker Compose, siguiendo patrones de data lake sobre object storage.   
- **Preparaci√≥n para orquestaci√≥n**: dise√±o del pipeline Bronze‚ÜíSilver‚ÜíGold como DAG l√≥gico listo para ser portado a Dagster/Airflow en las fases siguientes (Fase F).   

### 2.3 Programaci√≥n de Inteligencia Artificial

Aqu√≠ el proyecto se usa como **backend de datos para APIs y dashboards**:

- **APIs de servicio sobre Gold** (planificadas): dise√±o de endpoints FastAPI para exponer m√©tricas de `fact_raid_summary` y `fact_player_raid_stats` a otros m√≥dulos de IA y frontends.   
- **Dashboards ligeros**: integraci√≥n prevista con Streamlit y paneles web para explorar rendimiento por raid/jugador y validar visualmente las m√©tricas generadas en Gold.   
- **Preparaci√≥n de datasets de entrenamiento**: extracci√≥n de features limpias y agregadas desde Gold para consumo directo por librer√≠as de AutoML como PyCaret.   

### 2.4 Modelos de Inteligencia Artificial

En Modelos de IA la Capa Gold es la **fuente √∫nica de verdad**:

- **Clasificaci√≥n de raids**: uso de `fact_raid_summary` para predecir `raid_outcome` (Success/Wipe) en base a KPIs agregados de da√±o, curaci√≥n, muertes y tiempo.   
- **Clustering de estilos de juego**: aplicaci√≥n de algoritmos no supervisados sobre `fact_player_raid_stats` para extraer perfiles de jugadores (agresivo, consistente, glass cannon, etc.).    
- **Aprovechamiento de hardware GPU**: dise√±o del flujo para entrenar modelos pesados sobre Gold usando la RTX 3050 (CUDA) como acelerador.   

***

## 3. Arquitectura Medallion

```
Generador sint√©tico
        ‚îÇ
        ‚ñº
   [Bronze]  s3://bronze/wow_raid_events/v1/raid_id={id}/ingest_date={date}/batch_{n}.json
        ‚îÇ        JSON validado por Pydantic (schema-on-write)
        ‚îÇ
   run_bronze_to_silver.py
        ‚îÇ
        ‚ñº
   [Silver]  s3://silver/wow_raid_events/v1/raid_id={id}/event_date={date}/part-{n}.parquet
        ‚îÇ        Parquet + Snappy ‚Äî limpio, tipado, enriquecido
        ‚îÇ
   run_silver_to_gold.py --all
        ‚îÇ
        ‚ñº
   [Gold]   s3://gold/
        ‚îú‚îÄ‚îÄ dim_player/player_id=all/
        ‚îú‚îÄ‚îÄ dim_raid/raid_id={id}/
        ‚îú‚îÄ‚îÄ fact_raid_summary/raid_id={id}/event_date={date}/
        ‚îî‚îÄ‚îÄ fact_player_raid_stats/raid_id={id}/event_date={date}/
```

La arquitectura Medallion organiza los datos en tres capas de refinamiento progresivo que mejoran calidad, estructura y utilidad anal√≠tica.

### 3.1 Capa Bronze ‚Äì Raw / Ingesta

**Responsabilidad:** almacenar datos crudos tal y como llegan desde el receptor HTTP, pero ya validados por schema-on-write.

- **Formato:** JSON (array de eventos validados).  
- **Destino:** bucket `bronze` en MinIO.  
- **Key pattern (contrato de escritura):**  
  `wow_raid_events/v1/raidid={raid_id}/ingestdate={YYYY-MM-DD}/batch={uuid}.json`.  
- **Validaci√≥n:**  
  - Pydantic v2 en el propio receptor (schema-on-write).  
  - Rechazo con HTTP 400 ante eventos inv√°lidos, sin permitir su escritura en Bronze.  
- **Propiedades clave:**  
  - Inmutabilidad (append-only).  
  - Metadatos con `batch-id`, `event-count`, `ingest-timestamp` y `batch-source` para trazabilidad.

### 3.2 Capa Silver ‚Äì Clean / Refinada

**Responsabilidad:** ofrecer eventos limpios, tipados y enriquecidos, listos para uso anal√≠tico masivo.

- **Formato:** Apache Parquet + compresi√≥n Snappy.  
- **Destino:** bucket `silver` en MinIO.  
- **Particionamiento l√≥gico:**  
  `wow_raid_events/v1/raidid={raid_id}/eventdate={YYYY-MM-DD}/...`.  

**Transformaciones principales (m√≥dulo `SilverTransformer`):**

1. **Cast de tipos**  
   - `timestamp`, `ingest_timestamp`: string ISO 8601 ‚Üí `datetime64[ns, UTC]`.  
   - Num√©ricos (`damage_amount`, `healing_amount`, health_pct, resources) ‚Üí `float64`.  

2. **Deduplicaci√≥n**  
   - Eliminaci√≥n de duplicados por `event_id`.  
   - Conteo de duplicados eliminados en metadata.  

3. **Validaci√≥n de rangos**  
   - `health_pct` en rango [0, 100].  
   - Da√±os y curaciones no negativos.  

4. **Enriquecimiento**  
   - `ingest_latency_ms`: diferencia temporal entre `timestamp` e `ingest_timestamp`.  
   - `is_massive_hit`: flag para golpes de da√±o mayor a un umbral (ej. 10.000).  
   - `event_date`: fecha derivada para particionamiento y reporting.  

### 3.3 Capa Gold con modelo semidimensional

La capa Gold sigue un dise√±o **semidimensional**: adopta conceptos de modelado dimensional (hechos y dimensiones) pero manteniendo cierta flexibilidad propia de un data lake.

#### 3.3.1 Estructura l√≥gica de Gold

Gold est√° organizada en:

- **Dimensiones ‚Äúpeque√±as y estables‚Äù**:  
  - `dim_player`: informaci√≥n relativamente est√°tica de cada jugador (rol, clase, nombre, etc.).  
  - `dim_raid`: metadatos de cada raid (boss, dificultad, fecha, duraci√≥n esperada, etc.).   
- **Tablas de hechos particionadas**:  
  - `fact_raid_summary`: 1 fila por raid/encuentro, con m√©tricas agregadas globales (da√±o total, healing total, muertes, duraci√≥n real, `raid_outcome`, etc.).  
  - `fact_player_raid_stats`: 1 fila por jugador y raid, con DPS, HPS, ratio de cr√≠ticos, share de da√±o, muertes, etc.   

Este enfoque es ‚Äúsemi‚Äù dimensional porque:

- Se respeta la idea de **hechos + dimensiones** de Kimball, pero  
- Se mantiene el almacenamiento en object storage particionado (MinIO + Parquet), sin un warehouse r√≠gido, permitiendo lecturas directas desde motores anal√≠ticos (Pandas, DuckDB, PySpark).   

#### 3.3.2 Ventajas del dise√±o semidimensional

- **Lecturas anal√≠ticas eficientes**: las facts est√°n particionadas por `raid_id` y `event_date`, y las dimensiones son peque√±as, lo que permite joins baratos incluso en un entorno de laptop.   
- **Preparaci√≥n natural para BI y ML**: cualquier herramienta de BI o framework de ML puede consumir Gold casi ‚Äúplug-and-play‚Äù, sin necesitar una capa intermedia de modelado adicional.   
- **Evoluci√≥n controlada**: se pueden a√±adir nuevas m√©tricas o atributos dimensionales siguiendo schema evolution de Parquet sin romper la compatibilidad con c√≥digo existente.   

***

## 4. Importancia de la validaci√≥n en la ingesta Bronze

La validaci√≥n estricta en Bronze es una **decisi√≥n de arquitectura central** del proyecto: se aplica un enfoque **schema-on-write** con Pydantic v2 directamente en el receptor HTTP, antes de guardar cualquier evento en MinIO.   

### 4.1 Por qu√© schema-on-write (y no solo schema-on-read)

Sin validaci√≥n temprana:

- Bronze se llenar√≠a de **basura estructural**: tipos inconsistentes (`damage` como string, timestamps en formatos distintos), campos faltantes o valores imposibles (da√±o negativo, `health_pct > 100`).   
- Los problemas aparecer√≠an mucho m√°s tarde, al intentar construir Silver/Gold, donde localizar el origen de los errores es muy costoso y rompe la trazabilidad.   

Con schema-on-write:

- Cada evento pasa por modelos Pydantic que verifican tipos, rangos y enums (por ejemplo, `event_type`, `player_role`, `damage_amount >= 0`, `timestamp` no en el futuro).   
- Los eventos inv√°lidos se rechazan con un HTTP 400 y nunca llegan a Bronze, garantizando que **todo lo almacenado en Bronze ya es coherente a nivel de schema**.   

### 4.2 Beneficios para Silver, Gold y las asignaturas

- **Para BDA y Sistemas de Big Data**:  
  - Bronze act√∫a como registro inmutable pero ya ‚Äúlimpio de errores graves‚Äù, reduciendo la complejidad de Silver a limpieza l√≥gica (duplicados, outliers) y no a arreglar basura estructural.   
- **Para Programaci√≥n de IA y Modelos de IA**:  
  - Gold hereda esta calidad desde la base: los modelos de ML se entrenan con datos consistentes, evitando el cl√°sico problema de ‚Äúgarbage in, garbage out‚Äù en proyectos acad√©micos.     

En analog√≠a electr√≥nica, la validaci√≥n en Bronze equivale a poner un **filtro y protecci√≥n de entrada** en un sistema de adquisici√≥n de datos: no permites que una se√±al fuera de rango o con un formato imposible llegue al resto del circuito, protegiendo todos los componentes posteriores (Silver, Gold, ML, dashboards).   

***

## 5. Ejecutar el pipeline end-to-end

### Requisitos previos

```bash
# 1. Levantar MinIO
cd infra/minio && docker compose up -d

# 2. Activar entorno
mamba activate wow-telemetry
```


### Paso 1 ‚Äî Ingestar en Bronze (dataset de producci√≥n local)

```bash
# Dry-run (verificar rutas sin subir)
python src/etl/ingest_bronze_production.py --dry-run

# Ingesta real
python src/etl/ingest_bronze_production.py
# Esperado: ‚úÖ Subidos: 1010 archivos | üì¶ 546.9 MB
```


### Paso 2 ‚Äî ETL Bronze ‚Üí Silver

```bash
python src/etl/run_bronze_to_silver.py
# Esperado: ‚úÖ Exitosos: 1010 | üìä Filas totales: 505.000
```


### Paso 3 ‚Äî ETL Silver ‚Üí Gold (batch autom√°tico)

```bash
# Procesa TODAS las particiones disponibles en Silver autom√°ticamente
python -m src.etl.run_silver_to_gold --all

# Para re-procesar una partici√≥n concreta
python -m src.etl.run_silver_to_gold --raid-id raid001 --event-date 2026-02-25
```


### Paso 4 ‚Äî Inspecci√≥n y validaci√≥n de Gold

```bash
# Vista consolidada de todas las particiones + coherencia
python -m src.analytics.inspect_gold --all

# Deep-dive en una partici√≥n concreta
python -m src.analytics.inspect_gold --raid-id raid001 --event-date 2026-02-25
```


### Paso 5 ‚Äî Tests

```bash
pytest tests/ -q
```


***

## 6. Ingesta alternativa ‚Äî Receptor HTTP en tiempo real

Para el flujo event-driven original (Flask + generador HTTP + SSE):

```bash
# Terminal 1 ‚Äî Receptor HTTP
python src/api/receiver.py

# Terminal 2 ‚Äî Generador masivo
python src/generators/generate_massive_http.py \
  --num-raids 5 \
  --num-events-per-raid 50000 \
  --batch-size 500

# Monitorizaci√≥n SSE en tiempo real
# Abrir: tests/cliente_sse.html en el navegador
```


***

## 7. Estado del proyecto

### Fases completadas

| Fase | Descripci√≥n | Estado |
| :-- | :-- | :-- |
| **1** | Schema Pydantic v2 + Generador sint√©tico NumPy | ‚úÖ Completa |
| **2** | Receptor HTTP Flask + ingesta Bronze | ‚úÖ Completa |
| **3** | ETL Bronze ‚Üí Silver (Parquet, Snappy, particionado Hive) | ‚úÖ Completa |
| **4** | Gold Medallion (dim_player, dim_raid, facts, validaci√≥n) | ‚úÖ Completa |

### Roadmap

| Fase | Descripci√≥n | Tecnolog√≠a prevista |
| :-- | :-- | :-- |
| **E** | Procesamiento distribuido sobre Gold | PySpark + DuckDB + S3A ‚Üí MinIO |
| **F** | Table format + orquestaci√≥n | Delta Lake + Dagster |
| **G** | Visualizaci√≥n y APIs | Grafana + Apache Superset + FastAPI |
| **H** | Modelado IA | MLflow + PyCaret + CuDF (RTX 3050) |
| **I** | Datos reales | Warcraft Logs API |


***

## 8. Deuda t√©cnica documentada

| ID | Descripci√≥n | Severidad | Afecta |
| :-- | :-- | :-- | :-- |
| DT-01 | `MinIOStorageClient.list_objects()` no pagina (l√≠mite 1000 objetos) | Media | Silver con >1000 parquets por partici√≥n |
| DT-02 | Generador no produce eventos `player_death` en config actual | Baja | M√©trica `total_deaths` siempre = 0 en Gold |
| DT-03 | `dim_player.total_raids` siempre = 1 (upsert incremental pendiente) | Baja | An√°lisis multi-raid de jugadores |


***

## 9. Stack tecnol√≥gico

### Implementado

| Capa | Tecnolog√≠a |
| :-- | :-- |
| Validaci√≥n y schema | Pydantic v2, JSON Schema draft-07 |
| Generaci√≥n sint√©tica | NumPy (Normal, Bernoulli), UUID v4 |
| API e ingesta | Flask 3.x, python-dotenv |
| Object storage | MinIO (S3-compatible), boto3 |
| Procesamiento ETL | Pandas 2.x, PyArrow |
| Procesamiento distribuido | PySpark 3.5.4 (local*), DuckDB |
| Formato de almacenamiento | Apache Parquet + Snappy |
| Contenedores | Docker, Docker Compose |
| Testing | pytest |

### Planificado (Fases E‚ÄìI)

| Capa | Tecnolog√≠a |
| :-- | :-- |
| Table format | Delta Lake ‚Üí Apache Iceberg |
| Orquestaci√≥n | Dagster (asset-based) |
| Visualizaci√≥n | Grafana, Apache Superset |
| ML tracking | MLflow, PyCaret |
| Serving APIs | FastAPI |
| GPU computing | CuDF (RAPIDS), CUDA 12.x |


***

## 10. Reproducci√≥n del entorno

```bash
# Clonar
git clone https://github.com/Vincent0675/raid-savior.git
cd raid-savior

# Entorno
mamba create -n wow-telemetry python=3.10
mamba activate wow-telemetry
pip install -r requirements.txt

# Descargar JARs de Spark (una sola vez)
chmod +x scripts/download_spark_jars.sh
./scripts/download_spark_jars.sh

# Variables de entorno (.env)
S3_ENDPOINT_URL=http://localhost:9000
S3_ACCESS_KEY=minio
S3_SECRET_KEY=minio123
S3_BUCKET_BRONZE=bronze
S3_BUCKET_SILVER=silver
S3_BUCKET_GOLD=gold
FLASK_HOST=0.0.0.0
FLASK_PORT=5000

# Infraestructura
cd infra/minio && docker compose up -d
```

**Hardware de desarrollo:**
ASUS TUF Gaming A15 ¬∑ RTX 3050 4GB (CUDA) ¬∑ Pop!_OS 22.04 ¬∑ 16 GB RAM

***

## 11. Autor√≠a

**Autor:** Byron V. Blatch Rodriguez ‚Äî Estudiante Big Data e IA   
**GitHub:** [@Vincent0675](https://github.com/Vincent0675)   
**Profesor:** Francisco Javier Ortega   